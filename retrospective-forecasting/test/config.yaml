data:
  # Raw data location
  nextstrain_source: file://{{WORKING_DIRECTORY}}/test/metadata.tsv.xz
  usher_root: file://{{WORKING_DIRECTORY}}/test/
  cache_dir: test/cache
  redownload: true

  # Where are the processed datasets for modeling and evaluation stored?
  save_file:
    model: data/test/model.parquet
    eval: data/test/eval.parquet

  # What is the forecast date?
  # No sequences collected or reported after this date are included in the
  # modeling dataset.
  forecast_date:
    year: 2022
    month: 1
    day: 1

  # The modeling dataset will contain sequences collected and reported within
  # `[lower, 0]`, where 0 is the above `forecast_date`.
  # The evaluation dataset will contain sequences collected within `[lower, upper]`
  # and reported at any point before the date the data was accessed.
  horizon:
    lower: -90
    upper: 14

  # Which lineages should be included?
  # All others will be aggregated into "other".
  lineages: ["21A", "21I", "21J", "21K", "21L"]

  # Use subsetted Nextstrain data directly
  use_usher: True
  use_cladecombiner_as_of: False

forecasting:
  # Where (directory) should model output and visualizations be stored?
  save_dir: out/forecasts/test

  # Which models should be fit?
  models:
    - BaselineModel
    - IndependentDivisionsModel
    - HierarchicalDivisionsModel

  # MCMC configuration
  mcmc:
    warmup: 100
    samples: 100
    thinning: 2
    chains: 2
    convergence:
      # one of: "all" or "failing" to write a parquet of ESS and PSRF
      # for all parameters or only those failing
      report_mode: "failing"
      # Should diagnostic plots for all reported parameters be made?
      plot: False
      # ESS below this are considered bad
      ess_cutoff: 500
      # PSRF above this are considered bad
      psrf_cutoff: 1.01

  # Settings for HHS region, population-weighted aggregate forecasts
  survey:
    # Should the HHS region forecasts be made
    make: True
    # Should the HHS region forecasts be plotted (they are not evaluable!)
    plot: False
    # Where to get population size data from, path to a CSV
    pop_sizes: "pop_sizes_nst_est_2023.csv"

evaluation:
  # Where (directory) should model scores and visualizations be stored?
  save_dir: out/eval/test/

  # How should forecasts be evaluated?
  metrics:
    - ProportionsEvaluator
    - CountsEvaluator:
      - count_sampler: multinomial
