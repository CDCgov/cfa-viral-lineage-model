data:
  # Where are the processed datasets for modeling and evaluation stored?
  save_file:
    model: data/2022-early-omicron/model.parquet
    eval: data/2022-early-omicron/eval.parquet

  # What is the forecast date?
  # No sequences collected or reported after this date are included in the
  # modeling dataset.
  forecast_date:
    year: 2022
    month: 2
    day: 1

  # The modeling dataset will contain sequences collected and reported within
  # `[lower, 0]`, where 0 is the above `forecast_date`.
  # The evaluation dataset will contain sequences collected within `[lower, upper]`
  # and reported at any point before the date the data was accessed.
  horizon:
    lower: -90
    upper: 14

  # Which lineages should be included?
  # All others will be aggregated into "other".
  lineages: ["21A", "21I", "21J", "21K", "21L", "22C"]

forecasting:
  # Where (directory) should model output and visualizations be stored?
  save_dir: out/forecasts/2022-early-omicron/

  # Which models should be fit?
  models:
    - BaselineModel
    - IndependentDivisionsModel
    - HierarchicalDivisionsModel

  # MCMC configuration
  mcmc:
    warmup: 3000
    samples: 3000
    thinning: 3
    chains: 4
    convergence:
      # one of: "all" or "failing" to write a parquet of ESS and PSRF
      # for all parameters or only those failing
      report_mode: "failing"
      # Should diagnostic plots for all reported parameters be made?
      plot: True
      # ESS below this are considered bad
      ess_cutoff: 500
      # PSRF above this are considered bad
      psrf_cutoff: 1.01

  # Settings for HHS region, population-weighted aggregate forecasts
  survey:
    # Should the HHS region forecasts be made
    make: True
    # Should the HHS region forecasts be plotted (they are not evaluable!)
    plot: True
    # Where to get population size data from, path to a CSV
    pop_sizes: "pop_sizes_nst_est_2023.csv"

evaluation:
  # Where (directory) should model scores and visualizations be stored?
  save_dir: out/eval/2022-early-omicron

  # How should forecasts be evaluated?
  metrics:
    - ProportionsEvaluator
    - CountsEvaluator:
      - count_sampler: multinomial
